
@book{heim_semantics_1998,
	address = {Malden, MA},
	title = {Semantics in {Generative} {Grammar}},
	publisher = {Blackwell},
	author = {Heim, Irene and Kratzer, Angelika},
	year = {1998},
}

@article{grice_meaning_1957,
	title = {Meaning},
	volume = {66},
	issn = {0031-8108},
	url = {http://www.jstor.org/stable/2182440},
	doi = {10.2307/2182440},
	number = {3},
	urldate = {2021-02-20},
	journal = {The Philosophical Review},
	author = {Grice, H. P.},
	year = {1957},
	note = {Publisher: [Duke University Press, Philosophical Review]},
	pages = {377--388},
}

@book{potts_logic_2005,
	address = {New York},
	title = {The {Logic} of {Conventional} {Implicatures}},
	isbn = {978-0-19-927383-6},
	url = {http://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780199273829.001.0001/acprof-9780199273829},
	abstract = {This book revives the study of conventional implicatures in natural language semantics. The label ‘conventional implicature’ dates back to H. Paul Grice’s early work on the foundations of linguistic semantics and pragmatics. Since its introduction, it has seen many diverse applications, but it has never enjoyed a stable place in linguistic theory. This book seeks to change that. Grice’s original discussion is used as a key into two presently understudied areas of natural language: supplements (appositives, parentheticals, utterance modifiers) and expressives (epithets, honorifics). The account of both depends on a multidimensional theory in which individual sentences can express more than one independent meaning. The theory is logically and intuitively compositional, and it minimally extends a familiar kind of intensional logic, thereby providing an adaptable tool for general semantic analysis. The result is a linguistic theory that is accessible not only to linguists of all stripes, but also to philosophers of language, logicians, and computer scientists who have linguistic applications in mind.},
	language = {en\_US},
	urldate = {2021-04-13},
	publisher = {Oxford University Press},
	author = {Potts, Christopher},
	year = {2005},
	note = {Publication Title: The Logic of Conventional Implicatures},
	file = {Snapshot:/home/juliangrove/Documents/zotero/storage/SN72C6QR/acprof-9780199273829.html:text/html},
}

@incollection{grice_logic_1975,
	address = {New York},
	title = {Logic and {Conversation}},
	volume = {3, Speech Acts},
	booktitle = {Syntax and {Semantics}},
	publisher = {Academic Press},
	author = {Grice, H. P.},
	editor = {Cole, Peter and Morgan, Jerry L.},
	year = {1975},
	pages = {41--58},
}

@incollection{lewis_languages_1975,
	address = {New York},
	series = {Arguing about philosophy},
	title = {Languages and {Language}},
	booktitle = {Arguing about language},
	publisher = {Routledge},
	author = {Lewis, David K.},
	editor = {Byrne, Darragh and Kölbel, Max},
	year = {1975},
}

@article{hicks_chatgpt_2024,
	title = {{ChatGPT} is bullshit},
	volume = {26},
	issn = {1572-8439},
	url = {https://doi.org/10.1007/s10676-024-09775-5},
	doi = {10.1007/s10676-024-09775-5},
	abstract = {Recently, there has been considerable interest in large language models: machine learning systems which produce human-like text and dialogue. Applications of these systems have been plagued by persistent inaccuracies in their output; these are often called “AI hallucinations”. We argue that these falsehoods, and the overall activity of large language models, is better understood as bullshit in the sense explored by Frankfurt (On Bullshit, Princeton, 2005): the models are in an important way indifferent to the truth of their outputs. We distinguish two ways in which the models can be said to be bullshitters, and argue that they clearly meet at least one of these definitions. We further argue that describing AI misrepresentations as bullshit is both a more useful and more accurate way of predicting and discussing the behaviour of these systems.},
	language = {en},
	number = {2},
	urldate = {2025-07-24},
	journal = {Ethics and Information Technology},
	author = {Hicks, Michael Townsen and Humphries, James and Slater, Joe},
	month = jun,
	year = {2024},
	keywords = {Artificial intelligence, Artificial Intelligence, Assertion, Bullshit, ChatGPT, Computational Linguistics, Content, Formal Languages and Automata Theory, Frankfurt, Internetpsychology, Large language models, LLMs, Natural Language Processing (NLP), Symbolic AI},
	pages = {38},
	file = {Full Text PDF:/home/juliangrove/Documents/zotero/storage/XVFPFNE4/Hicks et al. - 2024 - ChatGPT is bullshit.pdf:application/pdf},
}

@article{licon_chatgpt_2025,
	title = {{ChatGPT} is {Bullshit} ({Partly}) {Because} {People} are {Bullshitters}},
	volume = {38},
	issn = {2210-5441},
	url = {https://doi.org/10.1007/s13347-025-00907-3},
	doi = {10.1007/s13347-025-00907-3},
	abstract = {In a recent article (‘ChatGPT is bullshit’), the authors argue that large language models (LLMs) like ChatGPT generate bullshit—a philosophical term coined by philosopher Harry Frankfurt that picks out convincing, but truth-insensitive content. The authors argue LLMs like ChatGPT are bullshitting machines. Here I defend a complementary account of why LLMs like ChatGPT produce bullshit: LLMs like ChatGPT are bullshit (partly) because people are bullshitters. Given that LLMs like ChatGPT predict and generate text based on large quantities of data from human language users, LLMs like ChatGPT would naturally reflect that fact—bullshit in, bullshit out. This paper then explores the incentives for people to bullshit—to manage reputations, to signal their intelligence, and to participate in the marketplace for bullshit—along with why such incentives will likely motivate people to use LLMs like ChatGPT to better bullshit each other.},
	language = {en},
	number = {2},
	urldate = {2025-07-24},
	journal = {Philosophy \& Technology},
	author = {Licon, Jimmy Alfonso},
	month = may,
	year = {2025},
	keywords = {Bullshit, Discourse Analysis, Incentives, Internetpsychology, Natural Language Processing (NLP), Philosophy of Language, Pragmatics, Reputation, Signaling Theory},
	pages = {75},
	file = {Full Text PDF:/home/juliangrove/Documents/zotero/storage/AQLFMRQ3/Licon - 2025 - ChatGPT is Bullshit (Partly) Because People are Bullshitters.pdf:application/pdf},
}

@article{frankfurt_bullshit_1986,
	title = {On {Bullshit}},
	volume = {6},
	url = {https://raritanquarterly.rutgers.edu/issue-index/all-articles/560-on-bullshit},
	abstract = {Raritan is a journal of wide-ranging inquiry publishing leading voices on history, literature, politics, and the arts since 1981. Edited by Jackson Lears.},
	language = {en-gb},
	number = {2},
	urldate = {2025-07-24},
	journal = {Raritan: A Quarterly Review {\textbar} Rutgers, The State University of New Jersey},
	author = {Frankfurt, Harry},
	year = {1986},
	file = {Snapshot:/home/juliangrove/Documents/zotero/storage/KGQ3PTVK/560-on-bullshit.html:text/html},
}

@book{winter_elements_2016,
	address = {Edinburgh},
	series = {Edinburgh {Advanced} {Textbooks} in {Linguistics}},
	title = {Elements of {Formal} {Semantics}},
	publisher = {Edinburgh University Press},
	author = {Winter, Yoad},
	year = {2016},
}
